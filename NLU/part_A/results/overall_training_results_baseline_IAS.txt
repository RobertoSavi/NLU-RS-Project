Model 0: [Result: Slot F1: 0.921 ± 0.003
 Intent Acc: 0.933 ± 0.002
, Optimizer: Adam, Hidden-size: 200, Embedding-size: 300, Learning-rate: 0.0001, Model: ModelIAS(
  (embedding): Embedding(866, 300, padding_idx=0)
  (utt_encoder): LSTM(300, 200, batch_first=True)
  (slot_out): Linear(in_features=200, out_features=130, bias=True)
  (intent_out): Linear(in_features=200, out_features=26, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)]
Model 1: [Result: Slot F1: 0.926 ± 0.003
 Intent Acc: 0.938 ± 0.004
, Optimizer: Adam, Hidden-size: 200, Embedding-size: 300, Learning-rate: 0.0005, Model: ModelIAS(
  (embedding): Embedding(866, 300, padding_idx=0)
  (utt_encoder): LSTM(300, 200, batch_first=True)
  (slot_out): Linear(in_features=200, out_features=130, bias=True)
  (intent_out): Linear(in_features=200, out_features=26, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)]
Model 2: [Result: Slot F1: 0.923 ± 0.004
 Intent Acc: 0.931 ± 0.006
, Optimizer: Adam, Hidden-size: 200, Embedding-size: 300, Learning-rate: 0.001, Model: ModelIAS(
  (embedding): Embedding(866, 300, padding_idx=0)
  (utt_encoder): LSTM(300, 200, batch_first=True)
  (slot_out): Linear(in_features=200, out_features=130, bias=True)
  (intent_out): Linear(in_features=200, out_features=26, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
)]
