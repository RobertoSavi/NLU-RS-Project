[Model: LSTM, With dropout, Optimizer: AdamW, Hidden-size: 250, Embedding-size: 350, Learning-rate: 1]
[Epoch: 1, PPL: 575270736883165733823015026688.0000, Best PPL: 575270736883165733823015026688.0000]
[Epoch: 2, PPL: 3291660157579487551722356736.0000, Best PPL: 3291660157579487551722356736.0000]
[Epoch: 3, PPL: 1871996508505364328997715968.0000, Best PPL: 1871996508505364328997715968.0000]
[Epoch: 4, PPL: 136419274285808160342016000.0000, Best PPL: 136419274285808160342016000.0000]
[Epoch: 5, PPL: 1053038522836988376347836416.0000, Best PPL: 136419274285808160342016000.0000]
[Epoch: 6, PPL: 92218192215704274275926016.0000, Best PPL: 92218192215704274275926016.0000]
[Epoch: 7, PPL: 110664512625023314464604160.0000, Best PPL: 92218192215704274275926016.0000]
[Epoch: 8, PPL: 1388432305449524350943232.0000, Best PPL: 1388432305449524350943232.0000]
[Epoch: 9, PPL: 1278531869874928375300096.0000, Best PPL: 1278531869874928375300096.0000]
[Epoch: 10, PPL: 57136889253393332023853056.0000, Best PPL: 1278531869874928375300096.0000]
[Epoch: 11, PPL: 399518228159587353100288.0000, Best PPL: 399518228159587353100288.0000]
[Epoch: 12, PPL: 803201623168807306526720.0000, Best PPL: 399518228159587353100288.0000]
[Epoch: 13, PPL: 59298599550012180817510400.0000, Best PPL: 399518228159587353100288.0000]
[Epoch: 14, PPL: 1443125902860068163072032768.0000, Best PPL: 399518228159587353100288.0000]
[Epoch: 15, PPL: 36579963912506171153448960.0000, Best PPL: 399518228159587353100288.0000]
[Epoch: 16, PPL: 3839141764797547176525824.0000, Best PPL: 399518228159587353100288.0000]
[Final PPL: 439659750357886398627840.0000]
