[Model: LSTM, With dropout, Optimizer: AdamW, Hidden-size: 250, Embedding-size: 350, Learning-rate: 0.0005]
[Epoch: 1, PPL: 388.1009, Best PPL: 388.1009]
[Epoch: 2, PPL: 270.7389, Best PPL: 270.7389]
[Epoch: 3, PPL: 224.3236, Best PPL: 224.3236]
[Epoch: 4, PPL: 198.8212, Best PPL: 198.8212]
[Epoch: 5, PPL: 182.8687, Best PPL: 182.8687]
[Epoch: 6, PPL: 171.0177, Best PPL: 171.0177]
[Epoch: 7, PPL: 162.3872, Best PPL: 162.3872]
[Epoch: 8, PPL: 155.4262, Best PPL: 155.4262]
[Epoch: 9, PPL: 150.3315, Best PPL: 150.3315]
[Epoch: 10, PPL: 146.1456, Best PPL: 146.1456]
[Epoch: 11, PPL: 143.0360, Best PPL: 143.0360]
[Epoch: 12, PPL: 140.3704, Best PPL: 140.3704]
[Epoch: 13, PPL: 138.2128, Best PPL: 138.2128]
[Epoch: 14, PPL: 136.7738, Best PPL: 136.7738]
[Epoch: 15, PPL: 135.3623, Best PPL: 135.3623]
[Epoch: 16, PPL: 133.8943, Best PPL: 133.8943]
[Epoch: 17, PPL: 133.3783, Best PPL: 133.3783]
[Epoch: 18, PPL: 132.8862, Best PPL: 132.8862]
[Epoch: 19, PPL: 132.1331, Best PPL: 132.1331]
[Epoch: 20, PPL: 132.3314, Best PPL: 132.1331]
[Epoch: 21, PPL: 132.1964, Best PPL: 132.1331]
[Epoch: 22, PPL: 132.1092, Best PPL: 132.1092]
[Epoch: 23, PPL: 132.0973, Best PPL: 132.0973]
[Epoch: 24, PPL: 132.0873, Best PPL: 132.0873]
[Epoch: 25, PPL: 131.9394, Best PPL: 131.9394]
[Epoch: 26, PPL: 132.5370, Best PPL: 131.9394]
[Epoch: 27, PPL: 132.5861, Best PPL: 131.9394]
[Epoch: 28, PPL: 133.4667, Best PPL: 131.9394]
[Epoch: 29, PPL: 133.3839, Best PPL: 131.9394]
[Epoch: 30, PPL: 134.2742, Best PPL: 131.9394]
[Final PPL: 119.8109]
