[Model: LSTM, Weight Tying Optimizer: SGD, Hidden-size: 350, Embedding-size: 350, Learning-rate: 1]
[Epoch: 1, PPL: 585.6275, Best PPL: 585.6275]
[Epoch: 2, PPL: 470.2585, Best PPL: 470.2585]
[Epoch: 3, PPL: 431.5117, Best PPL: 431.5117]
[Epoch: 4, PPL: 416.6071, Best PPL: 416.6071]
[Epoch: 5, PPL: 380.9288, Best PPL: 380.9288]
[Epoch: 6, PPL: 360.4177, Best PPL: 360.4177]
[Epoch: 7, PPL: 346.8426, Best PPL: 346.8426]
[Epoch: 8, PPL: 336.6243, Best PPL: 336.6243]
[Epoch: 9, PPL: 326.4379, Best PPL: 326.4379]
[Epoch: 10, PPL: 328.7742, Best PPL: 326.4379]
[Epoch: 11, PPL: 318.8798, Best PPL: 318.8798]
[Epoch: 12, PPL: 313.7062, Best PPL: 313.7062]
[Epoch: 13, PPL: 315.6823, Best PPL: 313.7062]
[Epoch: 14, PPL: 315.8265, Best PPL: 313.7062]
[Epoch: 15, PPL: 309.6104, Best PPL: 309.6104]
[Epoch: 16, PPL: 309.9300, Best PPL: 309.6104]
[Epoch: 17, PPL: 309.2119, Best PPL: 309.2119]
[Epoch: 18, PPL: 301.3467, Best PPL: 301.3467]
[Epoch: 19, PPL: 300.0685, Best PPL: 300.0685]
[Epoch: 20, PPL: 302.3279, Best PPL: 300.0685]
[Epoch: 21, PPL: 299.9022, Best PPL: 299.9022]
[Epoch: 22, PPL: 297.9353, Best PPL: 297.9353]
[Epoch: 23, PPL: 296.0574, Best PPL: 296.0574]
[Epoch: 24, PPL: 303.6555, Best PPL: 296.0574]
[Epoch: 25, PPL: 294.5599, Best PPL: 294.5599]
[Epoch: 26, PPL: 294.8314, Best PPL: 294.5599]
[Epoch: 27, PPL: 294.8021, Best PPL: 294.5599]
[Epoch: 28, PPL: 300.6931, Best PPL: 294.5599]
[Epoch: 29, PPL: 300.7027, Best PPL: 294.5599]
[Epoch: 30, PPL: 297.6154, Best PPL: 294.5599]
[Final PPL: 281.2011]
