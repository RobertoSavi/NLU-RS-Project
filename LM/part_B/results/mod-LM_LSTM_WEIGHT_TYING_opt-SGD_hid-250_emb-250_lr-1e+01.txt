[Model: LM_LSTM_WEIGHT_TYING, Optimizer: SGD, Hidden-size: 250, Embedding-size: 250, Learning-rate: 10]
[Epoch: 1, PPL: 463.1462, Best PPL: 463.1462]
[Epoch: 2, PPL: 367.9272, Best PPL: 367.9272]
[Epoch: 3, PPL: 328.2729, Best PPL: 328.2729]
[Epoch: 4, PPL: 318.6561, Best PPL: 318.6561]
[Epoch: 5, PPL: 304.0563, Best PPL: 304.0563]
[Epoch: 6, PPL: 289.0528, Best PPL: 289.0528]
[Epoch: 7, PPL: 273.1800, Best PPL: 273.1800]
[Epoch: 8, PPL: 271.4863, Best PPL: 271.4863]
[Epoch: 9, PPL: 265.1010, Best PPL: 265.1010]
[Epoch: 10, PPL: 256.3063, Best PPL: 256.3063]
[Epoch: 11, PPL: 258.9683, Best PPL: 256.3063]
[Epoch: 12, PPL: 264.5436, Best PPL: 256.3063]
[Epoch: 13, PPL: 255.5556, Best PPL: 255.5556]
[Epoch: 14, PPL: 244.5998, Best PPL: 244.5998]
[Epoch: 15, PPL: 253.9186, Best PPL: 244.5998]
[Epoch: 16, PPL: 241.8325, Best PPL: 241.8325]
[Epoch: 17, PPL: 245.0048, Best PPL: 241.8325]
[Epoch: 18, PPL: 244.6393, Best PPL: 241.8325]
[Epoch: 19, PPL: 242.7944, Best PPL: 241.8325]
[Epoch: 20, PPL: 239.0722, Best PPL: 239.0722]
[Epoch: 21, PPL: 244.7592, Best PPL: 239.0722]
[Epoch: 22, PPL: 243.3871, Best PPL: 239.0722]
[Epoch: 23, PPL: 240.2586, Best PPL: 239.0722]
[Epoch: 24, PPL: 245.3062, Best PPL: 239.0722]
[Epoch: 25, PPL: 244.9903, Best PPL: 239.0722]
[Final PPL: 222.5718]
