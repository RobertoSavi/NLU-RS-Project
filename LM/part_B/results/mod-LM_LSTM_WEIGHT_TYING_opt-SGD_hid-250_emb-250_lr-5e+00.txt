[Model: LM_LSTM_WEIGHT_TYING, Optimizer: SGD, Hidden-size: 250, Embedding-size: 250, Learning-rate: 5]
[Epoch: 1, PPL: 557.9834, Best PPL: 557.9834]
[Epoch: 2, PPL: 458.1167, Best PPL: 458.1167]
[Epoch: 3, PPL: 390.2081, Best PPL: 390.2081]
[Epoch: 4, PPL: 373.6495, Best PPL: 373.6495]
[Epoch: 5, PPL: 330.5820, Best PPL: 330.5820]
[Epoch: 6, PPL: 316.3204, Best PPL: 316.3204]
[Epoch: 7, PPL: 315.3270, Best PPL: 315.3270]
[Epoch: 8, PPL: 294.3862, Best PPL: 294.3862]
[Epoch: 9, PPL: 289.9484, Best PPL: 289.9484]
[Epoch: 10, PPL: 295.9490, Best PPL: 289.9484]
[Epoch: 11, PPL: 280.1122, Best PPL: 280.1122]
[Epoch: 12, PPL: 277.4066, Best PPL: 277.4066]
[Epoch: 13, PPL: 282.5926, Best PPL: 277.4066]
[Epoch: 14, PPL: 279.9307, Best PPL: 277.4066]
[Epoch: 15, PPL: 265.7106, Best PPL: 265.7106]
[Epoch: 16, PPL: 261.0458, Best PPL: 261.0458]
[Epoch: 17, PPL: 256.3972, Best PPL: 256.3972]
[Epoch: 18, PPL: 256.1478, Best PPL: 256.1478]
[Epoch: 19, PPL: 267.0725, Best PPL: 256.1478]
[Epoch: 20, PPL: 254.0082, Best PPL: 254.0082]
[Epoch: 21, PPL: 258.2241, Best PPL: 254.0082]
[Epoch: 22, PPL: 250.2116, Best PPL: 250.2116]
[Epoch: 23, PPL: 252.8306, Best PPL: 250.2116]
[Epoch: 24, PPL: 252.9713, Best PPL: 250.2116]
[Epoch: 25, PPL: 250.0008, Best PPL: 250.0008]
[Epoch: 26, PPL: 251.9421, Best PPL: 250.0008]
[Epoch: 27, PPL: 251.1552, Best PPL: 250.0008]
[Epoch: 28, PPL: 255.3550, Best PPL: 250.0008]
[Epoch: 29, PPL: 254.7981, Best PPL: 250.0008]
[Epoch: 30, PPL: 258.0863, Best PPL: 250.0008]
[Final PPL: 236.3404]
